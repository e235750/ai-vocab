# Dictionary Builder

WordWiseãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¾æ›¸ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚WordNetã‚„è£œè¶³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è‹±èªè¾æ›¸ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆãƒ»å‡¦ç†ã—ã¾ã™ã€‚

## ğŸ¯ æ¦‚è¦

Dictionary Builderã¯ã€ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰åŒ…æ‹¬çš„ãªè‹±èªè¾æ›¸ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™ï¼š

- **WordNet**: è‹±èªã®èªå½™ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆPrinceton Universityï¼‰
- **è£œè¶³ãƒ‡ãƒ¼ã‚¿**: è¿½åŠ ã®èªå½™ãƒ»å®šç¾©æƒ…å ±
- **ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®èªå½™ãƒ‡ãƒ¼ã‚¿

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

### ä¸»è¦æŠ€è¡“

- **Python 3.13**: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª
- **Poetry**: ä¾å­˜é–¢ä¿‚ç®¡ç†ãƒ»ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°
- **SQLite**: è»½é‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆé–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰
- **PostgreSQL**: æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹

### ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

- **NLTK**: è‡ªç„¶è¨€èªå‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆWordNet ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
- **Pandas**: ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»æ“ä½œ
- **SQLAlchemy**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ORM
- **Click**: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **Pydantic**: ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ»è¨­å®šç®¡ç†

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```text
dictionary_builder/
â”œâ”€â”€ build_database.py       # ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ pyproject.toml          # Poetryè¨­å®š
â”œâ”€â”€ Dockerfile              # Dockerè¨­å®š
â”œâ”€â”€ README.md              # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ data/                  # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â””â”€â”€ raw/               # ç”Ÿãƒ‡ãƒ¼ã‚¿
â”‚       â””â”€â”€ supplement.tsv # è£œè¶³ãƒ‡ãƒ¼ã‚¿ï¼ˆTSVå½¢å¼ï¼‰
â””â”€â”€ parsers/               # ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚µãƒ¼
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ supplement_parser.py # è£œè¶³ãƒ‡ãƒ¼ã‚¿ãƒ‘ãƒ¼ã‚µãƒ¼
    â””â”€â”€ wordnet_parser.py    # WordNetãƒ‘ãƒ¼ã‚µãƒ¼
```

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»ä½¿ç”¨æ–¹æ³•

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Poetryç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
cd dictionary_builder
poetry install

# ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
poetry shell

# NLTKãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰
python -c "import nltk; nltk.download('wordnet'); nltk.download('omw-1.4')"
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰

#### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

```bash
# å…¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¾æ›¸ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
python build_database.py

# ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®ã¿
python build_database.py --source wordnet
python build_database.py --source supplement

# å‡ºåŠ›å…ˆæŒ‡å®š
python build_database.py --output ./dictionary.db

# ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
python build_database.py --log-level DEBUG
```

#### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³

```bash
# ä½¿ç”¨å¯èƒ½ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³è¡¨ç¤º
python build_database.py --help
```

```text
Usage: build_database.py [OPTIONS]

Options:
  --source [wordnet|supplement|all]  ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹é¸æŠ [default: all]
  --output PATH                      å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ [default: dictionary.db]
  --log-level [DEBUG|INFO|WARNING|ERROR]  ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« [default: INFO]
  --clean                           æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰æ§‹ç¯‰
  --batch-size INTEGER              ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚º [default: 1000]
  --help                            ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
```

### Dockerå®Ÿè¡Œ

```bash
# Dockerã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
docker-compose run dictionary-builder

# ç‰¹å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ä»˜ãã§å®Ÿè¡Œ
docker-compose run dictionary-builder python build_database.py --source wordnet --clean
```

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

### WordNetãƒ‡ãƒ¼ã‚¿

```python
{
    "word": "example",
    "pos": "noun",  # å“è©ï¼ˆnoun, verb, adjective, adverbï¼‰
    "definitions": [
        {
            "definition": "a representative form or pattern",
            "examples": ["This is an example sentence."]
        }
    ],
    "synonyms": ["sample", "instance", "illustration"],
    "hypernyms": ["representation"],  # ä¸Šä½æ¦‚å¿µ
    "hyponyms": ["case", "precedent"]  # ä¸‹ä½æ¦‚å¿µ
}
```

### è£œè¶³ãƒ‡ãƒ¼ã‚¿å½¢å¼

TSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`data/raw/supplement.tsv`ï¼‰:

```tsv
word	pos	definition	japanese	examples	synonyms
example	noun	a representative form	ä¾‹ã€å®Ÿä¾‹	This is an example.	sample,instance
study	verb	to learn about something	å‹‰å¼·ã™ã‚‹	I study English.	learn,examine
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ

```sql
-- å˜èªãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE words (
    id INTEGER PRIMARY KEY,
    word VARCHAR(100) NOT NULL,
    pos VARCHAR(20) NOT NULL,
    frequency_rank INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å®šç¾©ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE definitions (
    id INTEGER PRIMARY KEY,
    word_id INTEGER REFERENCES words(id),
    definition TEXT NOT NULL,
    japanese TEXT,
    source VARCHAR(50) NOT NULL
);

-- ä¾‹æ–‡ãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE examples (
    id INTEGER PRIMARY KEY,
    definition_id INTEGER REFERENCES definitions(id),
    english TEXT NOT NULL,
    japanese TEXT
);

-- åŒç¾©èªãƒ†ãƒ¼ãƒ–ãƒ«
CREATE TABLE synonyms (
    id INTEGER PRIMARY KEY,
    word_id INTEGER REFERENCES words(id),
    synonym VARCHAR(100) NOT NULL
);
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¿½åŠ 

1. `parsers/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«æ–°ã—ã„ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ

```python
# parsers/custom_parser.py
from typing import List, Dict, Any

def parse_custom_data(file_path: str) -> List[Dict[str, Any]]:
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ"""
    words = []
    # ãƒ‘ãƒ¼ã‚¹ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
    return words
```

2. `build_database.py` ã«ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’çµ±åˆ

```python
from parsers.custom_parser import parse_custom_data

# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è¿½åŠ 
if source in ['custom', 'all']:
    custom_words = parse_custom_data('data/raw/custom.json')
    process_words(custom_words)
```

### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

```python
# ç‹¬è‡ªã®å‰å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
def preprocess_word(word_data: Dict[str, Any]) -> Dict[str, Any]:
    """å˜èªãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†"""
    # æ­£è¦åŒ–
    word_data['word'] = word_data['word'].lower().strip()
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if len(word_data['word']) < 2:
        return None
    
    return word_data

# å¾Œå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯
def postprocess_database(db_path: str):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¾Œå‡¦ç†"""
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    # çµ±è¨ˆæƒ…å ±æ›´æ–°
    # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
    pass
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### æœ€é©åŒ–è¨­å®š

```python
# ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚ºèª¿æ•´
BATCH_SIZE = 1000  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã«å¿œã˜ã¦èª¿æ•´

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
def optimize_database():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æœ€é©åŒ–"""
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    # çµ±è¨ˆæƒ…å ±æ›´æ–°
    # VACUUMå®Ÿè¡Œ
```

### å‡¦ç†æ™‚é–“ç›®å®‰

- **WordNetå…¨ä½“**: ç´„15-30åˆ†ï¼ˆç´„147,000èªï¼‰
- **è£œè¶³ãƒ‡ãƒ¼ã‚¿**: ç´„5-10åˆ†ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºä¾å­˜ï¼‰
- **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ**: ç´„5åˆ†

## ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ»å“è³ªç®¡ç†

### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ

```bash
# ãƒ†ã‚¹ãƒˆç”¨å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ
python build_database.py --source supplement --output test.db --batch-size 100
```

### ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯

```python
# ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
def validate_data_quality(db_path: str):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å“è³ªãƒã‚§ãƒƒã‚¯"""
    # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
    # NULLå€¤ãƒã‚§ãƒƒã‚¯
    # ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯
    # å¤–éƒ¨ã‚­ãƒ¼æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
```

## ğŸ³ Docker

### é–‹ç™ºç’°å¢ƒ

```bash
# é–‹ç™ºç”¨ã‚³ãƒ³ãƒ†ãƒŠå®Ÿè¡Œ
docker-compose run --rm dictionary-builder bash

# å¯¾è©±çš„ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
docker-compose run --rm dictionary-builder python -c "
from build_database import main
main()
"
```

### æœ¬ç•ªç’°å¢ƒ

```dockerfile
# æœ¬ç•ªç”¨Dockerã‚¤ãƒ¡ãƒ¼ã‚¸
FROM python:3.13-slim

WORKDIR /app
COPY . .

RUN pip install poetry && \
    poetry config virtualenvs.create false && \
    poetry install --no-dev

# NLTKãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
RUN python -c "import nltk; nltk.download('wordnet'); nltk.download('omw-1.4')"

CMD ["python", "build_database.py"]
```

## ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è©³ç´°

### WordNet

- **æä¾›å…ƒ**: Princeton University
- **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**: WordNet Licenseï¼ˆè‡ªç”±ä½¿ç”¨å¯èƒ½ï¼‰
- **å†…å®¹**: ç´„147,000ã®è‹±èªèªå½™
- **ç‰¹å¾´**: æ„å‘³çš„é–¢ä¿‚æ€§ï¼ˆåŒç¾©èªã€ä¸Šä½ãƒ»ä¸‹ä½æ¦‚å¿µï¼‰

### è£œè¶³ãƒ‡ãƒ¼ã‚¿

- **å½¢å¼**: TSVï¼ˆTab-Separated Valuesï¼‰
- **å†…å®¹**: æ—¥æœ¬èªç¿»è¨³ã€è¿½åŠ ä¾‹æ–‡ã€ç™ºéŸ³æƒ…å ±
- **ç”¨é€”**: WordNetãƒ‡ãƒ¼ã‚¿ã®è£œå®Œãƒ»æ‹¡å¼µ
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: [supplement.tsv](https://dbmx.net/dict/supplement.tsv)

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

### ãƒ‡ãƒ¼ã‚¿è¿½åŠ 

1. é©åˆ‡ãªå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™
2. å¯¾å¿œã™ã‚‹ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ
3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª
4. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„

- ãƒãƒƒãƒå‡¦ç†ã‚µã‚¤ã‚ºã®æœ€é©åŒ–
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã®æ”¹å–„
- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ã®æœ€é©åŒ–
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### NLTKãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„

```bash
# è§£æ±ºæ–¹æ³•
python -c "import nltk; nltk.download('wordnet')"
```

#### ãƒ¡ãƒ¢ãƒªä¸è¶³

```bash
# ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å°ã•ãã™ã‚‹
python build_database.py --batch-size 500
```

#### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼

```bash
# ã‚¯ãƒªãƒ¼ãƒ³ãƒ“ãƒ«ãƒ‰å®Ÿè¡Œ
python build_database.py --clean
```

## ğŸ“– å‚è€ƒè³‡æ–™

- [WordNet](https://wordnet.princeton.edu/)
- [NLTK Documentation](https://www.nltk.org/)
- [SQLAlchemy Documentation](https://docs.sqlalchemy.org/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Poetry Documentation](https://python-poetry.org/docs/)
